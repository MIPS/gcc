/* From fold_binary.  */

/* On GIMPLE bool != 0 is simply the canonical way to express a
   condition in COND_EXPRs and GIMPLE_CONDs.
   ???  Of course for assignments we still may want to strip those...  */
(simplify
 (ne @0 integer_zerop@1)
 (if (TREE_CODE (TREE_TYPE (@0)) == BOOLEAN_TYPE)
  /* On GENERIC comparisons can have arbitrary integer types.  */
  (if (GENERIC)
    (convert @0))
  /* On GIMPLE boolean types may have a precision != 1 thus the
     comparison serves as a more canonical required conversion.  */
  (if (GIMPLE && useless_type_conversion_p (type, TREE_TYPE (@0)))
    @0)))

/* From fold_comparison, in the order of transforms in there.  */

/* Transform comparisons of the form X +- C1 CMP C2 to X CMP C2 -+ C1.  */
(for cmp (lt le eq ge gt ne)
 (for op (plus minus)
  (simplify
   (cmp (op @0 INTEGER_CST@1) INTEGER_CST@2)
   (if ((cmp == NE_EXPR || cmp == EQ_EXPR
	 || TYPE_OVERFLOW_UNDEFINED (TREE_TYPE (@0)))
	&& (@3 = int_const_binop (op == MINUS_EXPR ? PLUS_EXPR : MINUS_EXPR, @2, @1))
	/* ???  fold_comparison here does, when @1 and @2 didn't have
	   TREE_OVERFLOW set, simplify the comparison to true/false
	   by using a staturated add.  */
	&& !TREE_OVERFLOW (@3))
    (cmp @0 @3)))))

/* Transform comparisons of the form X - Y CMP 0 to X CMP Y.  */
/* ??? The transformation is valid for the other operators if overflow
   is undefined for the type, but performing it here badly interacts
   with the transformation in fold_cond_expr_with_comparison which
   attempts to synthetize ABS_EXPR.  */
(for cmp (eq ne)
 (simplify
  (cmp (minus @0 @1) integer_zerop)
  (cmp @0 @1)))

/* For comparisons of pointers we can decompose it to a compile time
   comparison of the base objects and the offsets into the object.
   This requires at least one operand being an ADDR_EXPR or a
   POINTER_PLUS_EXPR to do more than the operand_equal_p test below.  */
#if 0
(for cmp in lt le eq ge gt ne
 (for op in addr pointer_plus
  (simplify
   (cmp:c (op@0 @1 @2) @3)
   (if (simplify_addr_comparison (@0, @3, @@))))))
#endif

/* Simplify X * C1 CMP 0 to X CMP 0 if C1 is not zero.  */
(for op (lt le eq ne ge gt)
  (simplify
    (op (mult @0 INTEGER_CST@1) integer_zerop@2)
    /* In fold-const.c we have this and the following pattern
       combined because there we can "compute" the operator
       to use by using swap_tree_comparison.  Here we manage
       to use only two patterns by swapping the operands instead
       of changing the comparison code.  */
    (if (TYPE_OVERFLOW_UNDEFINED (TREE_TYPE (@0)))
     (if (tree_int_cst_sgn (@1) > 0)
      (op @0 @2))
     (if (tree_int_cst_sgn (@1) < 0)
      (op @2 @0)))))

#if 0
/* If this is comparing a constant with a MIN_EXPR or a MAX_EXPR of a
   constant, we can simplify it.  */
(for op in min max
 (for cmp in eq gt
  (cmp (op @0 INTEGER_CST@1) INTEGER_CST@2)
  (if (op == MAX_EXPR && tree_int_cst_compare (@1, @2) == 0)
   (le @0 @2))
  (if (
      )
   /* ??? optimize_minmax_comparison handles ne, lt and le by
      recursing with an inverted comparison and then inverting
      the result.  Or combining equality and gt with truth_or.   */)
#endif

/* Simplify comparison of something with itself.  For IEEE
   floating-point, we can only do some of these simplifications.  */
(for cmp (ge le)
 (simplify
  (cmp @0 @0)
  (eq @0 @0)))
(simplify
 (eq @0 @0)
 (if (! FLOAT_TYPE_P (TREE_TYPE (@0))
      || ! HONOR_NANS (TYPE_MODE (TREE_TYPE (@0))))
  { constant_boolean_node (true, type); }))
(for cmp (ne gt lt)
 (simplify
  (cmp @0 @0)
  (if (cmp != NE_EXPR
       || ! FLOAT_TYPE_P (TREE_TYPE (@0))
       || ! HONOR_NANS (TYPE_MODE (TREE_TYPE (@0))))
   { constant_boolean_node (false, type); })))

/* Need to split up the cases in twoval_comparison_p.  */

#if 0
/* We can fold X/C1 op C2 where C1 and C2 are integer constants
   into a single range test.  */
(for cmp in lt le eq ge gt ne
 (for div in trunc_div exact_div
  (simplify
   (cmp (div @0 INTEGER_CST@1) INTEGER_CST)
   (if (!integer_zerop (@1))
   /* ???  Need to think about what fold_div_compare does.  IMHO
      we can unconditionally build a
      (unsigned)@0 +- CST <= CST'
      range check.  */
  ))))
#endif

/* Fold ~X op ~Y as Y op X.  */
(for cmp (lt le eq ge gt ne)
 (simplify
  (cmp (bit_not @0) (bit_not @1))
  (cmp @1 @0)))

/* Fold ~X op C as X op' ~C, where op' is the swapped comparison.  */
(for cmp (lt le eq ge gt ne)
 (simplify
  (cmp (bit_not @0) @1)
  /* ???  (for cst in INTEGER_CST VECTOR_CST) is not supported yet.  */
  (if ((TREE_CODE (@1) == INTEGER_CST || TREE_CODE (@1) == VECTOR_CST))
  /* fold_comparison uses swapped 'cmp' to canonicalize the result
     (constants second operand), swapping 'cmp' isn't available so we
     cheat here and leave canonicalization to re-simplifying.  */
   (cmp (bit_not @1) @0))))
