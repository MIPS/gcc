/* Match-and-simplify patterns for shared GENERIC and GIMPLE folding.
   This file is consumed by genmatch which produces gimple-match.c
   from it.

   Copyright (C) 2014 Free Software Foundation, Inc.
   Contributed by Richard Biener <rguenther@suse.de>

This file is part of GCC.

GCC is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free
Software Foundation; either version 3, or (at your option) any later
version.

GCC is distributed in the hope that it will be useful, but WITHOUT ANY
WARRANTY; without even the implied warranty of MERCHANTABILITY or
FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
for more details.

You should have received a copy of the GNU General Public License
along with GCC; see the file COPYING3.  If not see
<http://www.gnu.org/licenses/>.  */

/* Simple constant foldings to substitute gimple_fold_stmt_to_constant_2.  */
(match_and_simplify
  (plus @0 integer_zerop)
  @0)
(match_and_simplify
  (pointer_plus @0 integer_zerop)
  @0)
(match_and_simplify
  (minus @0 integer_zerop)
  @0)
(match_and_simplify
  (minus @0 @0)
  { build_zero_cst (type); })
(match_and_simplify
  (mult @0 integer_zerop@1)
  @1)
(match_and_simplify
  (mult @0 integer_onep)
  @0)
/* Make sure to preserve divisions by zero.  This is the reason why
   we don't simplify x / x to 1 or 0 / x to 0.  */
(match_and_simplify
  (trunc_div @0 integer_onep)
  @0)
(match_and_simplify
  (trunc_mod @0 integer_onep)
  { build_zero_cst (type); })
/* Same applies to modulo operations, but fold is inconsistent here
   and simplifies 0 % x to 0.  */
(match_and_simplify
  (trunc_mod integer_zerop@0 @1)
  if (!integer_zerop (@1))
  @0)
(match_and_simplify
  (bit_ior @0 integer_zerop)
  @0)
(match_and_simplify
  (bit_ior @0 integer_all_onesp@1)
  @1)
(match_and_simplify
  (bit_and @0 integer_all_onesp)
  @0)
(match_and_simplify
  (bit_and @0 integer_zerop@1)
  @1)
(match_and_simplify
  (bit_xor @0 integer_zerop)
  @0)
(match_and_simplify
  (bit_xor @0 @0)
  { build_zero_cst (type); })
/* tree-ssa/ifc-pr44710.c requires a < b ? c : d to fold to 1.
   ???  probably runs into issue of recursive folding of a < b op0.  */
/* tree-ssa/ssa-ccp-16.c wants to fold "hello"[i_2] to 0
   (fold_const_aggregate_ref_1).  */
/* tree-ssa/ssa-ccp-19.c wants to fold &a1_3->i to &MEM[(void *)&a]
   (get_addr_base_and_unit_offset_1). */
/* tree-ssa/ssa-ccp-22.c wants to fold b_2(D) <= t_1 to 1.
   We are missing compare constant folding to type boundaries.  */

/* The following is simplification done by gimple_fold_stmt_to_constant_1
   to aid propagation engines, producing is_gimple_min_invariants from
   invariant_addr + cst.  It may not be generally wanted
   (builtin-object-size) and thus may want to be restricted to 'simple'
   forms like &mem-ref or &decl.  */
(match_and_simplify
  (pointer_plus (addr@2 @0) INTEGER_CST_P@1)
  if (is_gimple_min_invariant (@2))
  {
    HOST_WIDE_INT off;
    tree base = get_addr_base_and_unit_offset (@0, &off);
    off += tree_to_uhwi (@1);
    /* Now with that we should be able to simply write
       (addr (mem_ref (addr @base) (plus @off @1)))  */
    build1 (ADDR_EXPR, type,
            build2 (MEM_REF, TREE_TYPE (TREE_TYPE (@2)),
	    	    build_fold_addr_expr (base),
	            build_int_cst (ptr_type_node, off)));
  })


/* Transforms formerly done by tree-ssa-forwprop.c:associate_plusminus  */

/* ???  Have match_and_simplify groups guarded with common
   predicates on the outermost type?  */

/* Contract negates.  */
(match_and_simplify
  (plus @0 (negate @1))
  if (!TYPE_SATURATING (type))
  (minus @0 @1))
(match_and_simplify
  (minus @0 (negate @1))
  if (!TYPE_SATURATING (type))
  (plus @0 @1))
(match_and_simplify
  (plus (negate @0) @1)
  if (!TYPE_SATURATING (type))
  (minus @1 @0))

/* Change to even more free-form like

simplify (plus@2 (negate @0) @1)
if (!TYPE_SATURATING (TREE_TYPE (@2)))
to (minus @1 @0)

   so only patterns are lispy, the rest not?  */

/* Match patterns that allow contracting a plus-minus pair
   irrespective of overflow issues.
   ???  !TYPE_SATURATING condition missing.
   ???  !FLOAT_TYPE_P && !FIXED_POINT_TYPE_P condition missing
   because of saturation to +-Inf.  */

/* (A +- B) - A -> +-B.  */
(match_and_simplify
  (MINUS_EXPR (PLUS_EXPR @0 @1) @0)
  if (!TYPE_SATURATING (TREE_TYPE (@0))
      && !FLOAT_TYPE_P (TREE_TYPE (@0)) && !FIXED_POINT_TYPE_P (TREE_TYPE (@0)))
  @1)
(match_and_simplify
  (MINUS_EXPR (MINUS_EXPR @0 @1) @0)
  (NEGATE_EXPR @1))
/* (A +- B) -+ B -> A.  */
(match_and_simplify
  (MINUS_EXPR (PLUS_EXPR @0 @1) @1)
  @0)
(match_and_simplify
  (PLUS_EXPR (MINUS_EXPR @0 @1) @1)
  @0)
/* (CST +- A) +- CST -> CST' +- A.  */
/* match_and_simplify handles constant folding for us so we can
   implement these as re-association patterns.
   Watch out for operand order and constant canonicalization
   we do!  A - CST -> A + -CST, CST + A -> A + CST.  */
(match_and_simplify
  (PLUS_EXPR (PLUS_EXPR @0 INTEGER_CST_P@1) INTEGER_CST_P@2)
  (PLUS_EXPR @0 (PLUS_EXPR @1 @2)))
(match_and_simplify
  (PLUS_EXPR (MINUS_EXPR INTEGER_CST_P@0 @1) INTEGER_CST_P@2)
  (MINUS_EXPR (PLUS_EXPR @0 @2) @1))
/* TODO:
   (A +- CST) +- CST  ->  A +- CST
   ~A + A             ->  -1
   ~A + 1             ->  -A
   A - (A +- B)       ->  -+ B
   A +- (B +- A)      ->  +- B
   CST +- (CST +- A)  ->  CST +- A
   CST +- (A +- CST)  ->  CST +- A
   A + ~A             ->  -1
   (T)(P + A) - (T)P  -> (T)A
 */

/* ~A + A -> -1 */
(match_and_simplify
  (plus (bit_not @0) @0)
  { build_all_ones_cst (type); })
(match_and_simplify
  (plus @0 (bit_not @0))
  { build_all_ones_cst (type); })

/* ~A + 1 -> -A */
(match_and_simplify
  (plus (bit_not @0) integer_onep)
  if (INTEGRAL_TYPE_P (TREE_TYPE (@0)))
  (negate @0)) 

/* A - (A +- B) -> -+ B */
(match_and_simplify
  (minus @0 (plus @0 @1))
  (negate @0))

(match_and_simplify
  (minus @0 (minus @0 @1))
  @1)

/* (T)(P + A) - (T)P -> (T) A */
(match_and_simplify
  (minus (convert (pointer_plus @0 @1))
	 (convert @0))
  (convert @1)) 

/* Patterns required to avoid SCCVN testsuite regressions.  */

/* (x >> 31) & 1 -> (x >> 31).  Folding in fold-const is more
   complicated here, it does
     Fold (X << C1) & C2 into (X << C1) & (C2 | ((1 << C1) - 1))
     (X >> C1) & C2 into (X >> C1) & (C2 | ~((type) -1 >> C1))
     if the new mask might be further optimized.  */
(match_and_simplify
  (bit_and (rshift@0 @1 INTEGER_CST_P@2) integer_onep)
  if (compare_tree_int (@2, TYPE_PRECISION (TREE_TYPE (@1)) - 1) == 0)
  @0)

/* COMPLEX_EXPR and REALPART/IMAGPART_EXPR cancellations.  */
(match_and_simplify
  (complex (realpart @0) (imagpart @0))
  @0)
(match_and_simplify
  (realpart (complex @0 @1))
  @0)
(match_and_simplify
  (imagpart (complex @0 @1))
  @1)

/* One unary pattern.  */

/* fold_negate_exprs convert - (~A) to A + 1.  */
(match_and_simplify
  (negate (bit_not @0))
  if (INTEGRAL_TYPE_P (TREE_TYPE (@0)))
  (plus @0 { build_int_cst (TREE_TYPE (@0), 1); } ))

/* One ternary pattern.  */

/* Due to COND_EXPRs weirdness in GIMPLE the following won't work
   without some hacks in the code generator.  */
(match_and_simplify
  (cond (bit_not @0) @1 @2)
  (cond @0 @2 @1))

/* match-and-simplify handles constant folding so we
   can just do the decomposition here.  */
(match_and_simplify
  (fma INTEGER_CST_P@0 INTEGER_CST_P@1 @3)
  (plus (mult @0 @1) @3))

/* One builtin function to atom.  */
(match_and_simplify
  (BUILT_IN_SQRT (mult @0 @0))
  @0)
/* One builtin function to builtin function.  */
(match_and_simplify
  (BUILT_IN_CABS (complex @0 real_zerop))
  (BUILT_IN_FABS @0))
(match_and_simplify
  (BUILT_IN_CABS (complex real_zerop @0))
  (BUILT_IN_FABS @0))
/* One builtin function to expr.  */
(match_and_simplify
  (BUILT_IN_CABS (complex @0 @0))
  (mult (BUILT_IN_FABS @0) { build_real (TREE_TYPE (@0), real_value_truncate (TYPE_MODE (TREE_TYPE (@0)), dconst_sqrt2 ())); }))
/* One nested fn.  */
(match_and_simplify
  (mult (BUILT_IN_POW @0 @1) @0)
  (BUILT_IN_POW @0 (PLUS_EXPR @1 { build_one_cst (TREE_TYPE (@1)); })))
(match_and_simplify
  (mult @0 (BUILT_IN_POW @0 @1))
  (BUILT_IN_POW @0 (PLUS_EXPR @1 { build_one_cst (TREE_TYPE (@1)); })))
(match_and_simplify
  (BUILT_IN_POW @0 REAL_CST_P@1)
  /* This needs to be conditionalized on flag_unsafe_math_optimizations,
     but we keep it for now to exercise function re-optimization.
     It makes gcc.dg/pr43419.c FAIL execution though.  */
  if (REAL_VALUES_EQUAL (TREE_REAL_CST (@1), dconsthalf))
  (BUILT_IN_SQRT @0))

/* TODO bitwise patterns:
1] x & x -> x
2] x & 0 -> 0
3] x & -1 -> x
4] x & ~x -> 0
5] ~x & ~y -> ~(x | y)
6] ~x | ~y -> ~(x & y)
7] x & (~x | y) -> y & x
8] (x | CST1) & CST2  ->  (x & CST2) | (CST1 & CST2)
9] x ^ x -> 0
10] x ^ ~0 -> ~x
11] (x | y) & x -> x
12] (x & y) | x -> x
13] (~x | y) & x -> x & y
14] (~x & y) | x -> x | y
15] ((a & b) & ~a) & ~b -> 0
16] ~~x -> x
*/

/* x & x -> x */
(match_and_simplify
  (bit_and @0 @0)
  if (INTEGRAL_TYPE_P (TREE_TYPE (@0)))
  @0)

/* x & ~x -> 0 */
(match_and_simplify
  (bit_and @0 (bit_not @0))
  if (INTEGRAL_TYPE_P (TREE_TYPE (@0)))
  { build_int_cst (type, 0); })

/* ~x & ~y -> ~(x | y) */
(match_and_simplify
  (bit_and (bit_not @0) (bit_not @1))
  if (INTEGRAL_TYPE_P (TREE_TYPE (@0)))
  (bit_not (bit_ior @0 @1)))

/* ~x | ~y -> ~(x & y) */
(match_and_simplify
  (bit_ior (bit_not @0) (bit_not @1))
  if (INTEGRAL_TYPE_P (TREE_TYPE (@0)))
  (bit_not (bit_and @0 @1)))

/* x & (~x | y) -> y & x */
(match_and_simplify
  (bit_and @0 (bit_ior (bit_not @0) @1))
  if (INTEGRAL_TYPE_P (TREE_TYPE (@0)))
  (bit_and @1 @0))

/* (x | CST1) & CST2 -> (x & CST2) | (CST1 & CST2) */
(match_and_simplify
  (bit_and (bit_ior @0 INTEGER_CST_P@1) INTEGER_CST_P@2)
  if (INTEGRAL_TYPE_P (TREE_TYPE (@0)))
  (bit_ior (bit_and @0 @2) (bit_and @1 @2)))

/* x ^ ~0 -> ~x */
(match_and_simplify
  (bit_xor @0 integer_all_onesp@1)
  (bit_not @0))

/* (x | y) & x -> x */
(match_and_simplify
  (bit_and (bit_ior @0 @1) @0)
  if (INTEGRAL_TYPE_P (TREE_TYPE (@0)))
  @0)

/* (x & y) | x -> x */
(match_and_simplify
  (bit_ior (bit_and @0 @1) @0)
  if (INTEGRAL_TYPE_P (TREE_TYPE (@0)))
  @0)

/* (~x | y) & x -> x & y */
(match_and_simplify
  (bit_and (bit_ior (bit_not @0) @1) @0)
  if (INTEGRAL_TYPE_P (TREE_TYPE (@0)))
  (bit_and @0 @1))

/* (~x & y) | x -> x | y */
(match_and_simplify
  (bit_ior (bit_and (bit_not @0) @1) @0)
  if (INTEGRAL_TYPE_P (TREE_TYPE (@0)))
  (bit_ior @0 @1))

/* ~~x -> x */
(match_and_simplify
  (bit_not (bit_not @0))
  if (INTEGRAL_TYPE_P (TREE_TYPE (@0)))
  @0)

/* ((a & b) & ~a) -> 0 */
(match_and_simplify
  (bit_and (bit_and @0 @1) (bit_not @0))
  if (INTEGRAL_TYPE_P (TREE_TYPE (@0)))
  { build_int_cst (type, 0); })

/* ????s

   We cannot reasonably match vector CONSTRUCTORs or vector constants
   without using special predicates.  Nor can we reasonably generate
   variable-length stuff with pattern expressions.

 */
